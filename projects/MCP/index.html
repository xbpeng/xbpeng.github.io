---
layout: default
title: "MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies"
---

<center><h1>{{ page.title }}</h1></center>

<td>
	<center>
		arXiv Preprint 2019<br>
		<br>
		<nobr>Xue Bin Peng</nobr> &emsp;&emsp; <nobr>Michael Chang</nobr> &emsp;&emsp; <nobr>Grace Zhang</nobr> &emsp;&emsp; <nobr>Pieter Abbeel</nobr> &emsp;&emsp; <nobr>Sergey Levine</nobr><br>
		<br>
		<nobr>University of California, Berkeley</nobr><br>
		<br>
		<img style="vertical-align:middle" src="mcp_teaser.png"  width="100%" height="inherit"/>		
	</center>
</td>

<br>
	
<td>
	<hr>
	<h3 style="margin-bottom:10px;">Abstract</h3>
	Humans are able to perform a myriad of sophisticated tasks by drawing upon skills
	acquired through prior experience. For autonomous agents to have this capability,
	they must be able to extract reusable skills from past experience that can be 
	recombined in new ways for subsequent tasks. Furthermore, when controlling complex
	high-dimensional morphologies, such as humanoid bodies, tasks often require
	coordination of multiple skills simultaneously.  Learning discrete primitives for
	every combination of skills quickly becomes prohibitive. Composable primitives
	that can be recombined to create a large variety of behaviors can be more suitable
	for modeling this combinatorial explosion. In this work, we propose multiplicative
	compositional policies (MCP), a method for learning reusable motor skills that
	can be composed to produce a range of complex behaviors. Our method factorizes
	an agent's skills into a collection of primitives, where multiple primitives can be
	activated simultaneously via multiplicative composition. This flexibility allows the
	primitives to be transferred and recombined to elicit new behaviors as necessary
	for novel tasks.  We demonstrate that MCP is able to extract composable skills
	for highly complex simulated characters from pre-training tasks, such as motion
	imitation, and then reuse these skills to solve challenging continuous control tasks,
	such as dribbling a soccer ball to a goal, and picking up an object and transporting
	it to a target location.
</td>

<td>
	<h3> Paper: [<a href="2019_MCP.pdf">PDF</a>] &nbsp; &nbsp; &nbsp; Preprint: [<a href="https://arxiv.org/abs/1905.09808">arXiv</a>] </h3>
</td>

<tr>
		<h3 style="margin-bottom:10px;">Video</h3>
		<iframe width="560" height="315" src="https://www.youtube.com/embed/ChxSx8-sX_c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</tr>
	
<br>
<br>

<h3 style="margin-bottom:0px;">Bibtex</h3>
<pre>
@article{
	MCPPeng19,
	author = {Xue Bin Peng and Michael Chang and Grace Zhang and Pieter Abbeel and Sergey Levine},
	title = {MCP: Learning Composable Hierarchical Control with Multiplicative Compositional Policies},
	journal = {CoRR},
	volume = {abs/1905.09808},
	year = {2019},
	url = {http://arxiv.org/abs/1905.09808},
	archivePrefix = {arXiv},
	eprint = {1905.09808},
	timestamp = {Wed, 29 May 2019 11:27:50 +0200},
	biburl = {https://dblp.org/rec/bib/journals/corr/abs-1905-09808},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
</pre>
