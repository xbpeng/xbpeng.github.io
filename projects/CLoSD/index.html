---
layout: default
title: "CLoSD: Closing the Loop Between Simulation and Diffusion for Multi-Task Character Control"
---

<center><h1>{{ page.title }}</h1></center>

<td>
	<center>
		International Conference on Learning Representations (ICLR 2025)<br>
		<b> Spotlight </b> <br>
		<br>
		<nobr>Guy Tevet (1, 2)</nobr> &emsp;&emsp; <nobr>Sigal Raab (1)</nobr> &emsp;&emsp; <nobr>Setareh Cohan (2)</nobr> &emsp;&emsp; <nobr>Daniele Reda (2)</nobr> &emsp;&emsp; <nobr>Zhengyi Luo (3)</nobr> &emsp;&emsp; <nobr>Xue Bin Peng (4, 5)</nobr> &emsp;&emsp; <nobr>Amit H. Bermano (1)</nobr> &emsp;&emsp; <nobr>Michiel van de Panne (2)</nobr> <br>
		<br>
		<nobr> (1) Tel-Aviv University</nobr> &emsp;&emsp; <nobr>(2) University of British Columbia</nobr> &emsp;&emsp; <nobr>(3) Carnegie Mellon University</nobr> &emsp;&emsp; <nobr>(4) Simon Fraser University</nobr> &emsp;&emsp; <nobr>(5) NVIDIA</nobr><br>
		<br>
		<img style="vertical-align:middle" src="CLoSD_teaser.png"  width="100%" height="inherit"/>		
	</center>
</td>

<br>
	
<td>
	<hr>
	<h3 style="margin-bottom:10px;">Abstract</h3>
	Motion diffusion models and Reinforcement Learning (RL) based control for
	physics-based simulations have complementary strengths for human motion generation.
	The former is capable of generating a wide variety of motions, adhering
	to intuitive control such as text, while the latter offers physically plausible motion
	and direct interaction with the environment. In this work, we present a method
	that combines their respective strengths. CLoSD is a text-driven RL physicsbased
	controller, guided by diffusion generation for various tasks. Our key insight
	is that motion diffusion can serve as an on-the-fly universal planner for a
	robust RL controller. To this end, CLoSD maintains a closed-loop interaction between
	two modules â€” a Diffusion Planner (DiP), and a tracking controller. DiP
	is a fast-responding autoregressive diffusion model, controlled by textual prompts
	and target locations, and the controller is a simple and robust motion imitator that
	continuously receives motion plans from DiP and provides feedback from the environment.
	CLoSD is capable of seamlessly performing a sequence of different
	tasks, including navigation to a goal location, striking an object with a hand or
	foot as specified in a text prompt, sitting down, and getting up.
</td>

<td>
	<h3> Paper: [<a href="CLoSD_2025.pdf">PDF</a>] &nbsp; &nbsp; &nbsp; Code: [<a href="https://github.com/GuyTevet/CLoSD">GitHub</a>] &nbsp; &nbsp; &nbsp; Webpage: [<a href="https://guytevet.github.io/CLoSD-page/">Link</a>] &nbsp; &nbsp; &nbsp; Preprint: [<a href="https://arxiv.org/abs/2410.03441">arXiv</a>] </h3>
</td>

<tr>
	<h3 style="margin-bottom:10px;">Video</h3>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/O1tzbiDMW8U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
</tr>
	
<br>
<br>

<h3 style="margin-bottom:0px;">Bibtex</h3>
<pre>
@inproceedings{
    tevet2025closd,
    title={CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control},
    author={Guy Tevet and Sigal Raab and Setareh Cohan and Daniele Reda and Zhengyi Luo and Xue Bin Peng and Amit Haim Bermano and Michiel van de Panne},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=pZISppZSTv}
}
</pre>
